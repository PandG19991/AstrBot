# éƒ¨ç½²ä¸è¿ç»´æ–‡æ¡£

## ğŸ“‘ ç›®å½•
- [1. éƒ¨ç½²æ¶æ„è®¾è®¡](#1-éƒ¨ç½²æ¶æ„è®¾è®¡)
- [2. ç¯å¢ƒé…ç½®](#2-ç¯å¢ƒé…ç½®)
- [3. éƒ¨ç½²æµç¨‹](#3-éƒ¨ç½²æµç¨‹)
- [4. ç›‘æ§ä¸å‘Šè­¦](#4-ç›‘æ§ä¸å‘Šè­¦)
- [5. æ—¥å¿—ç®¡ç†](#5-æ—¥å¿—ç®¡ç†)
- [6. æ•°æ®å¤‡ä»½ä¸ç¾å¤‡](#6-æ•°æ®å¤‡ä»½ä¸ç¾å¤‡)
- [7. ç‰ˆæœ¬å‡çº§ä¸å›æ»š](#7-ç‰ˆæœ¬å‡çº§ä¸å›æ»š)
- [8. æ•…éšœåº”æ€¥å¤„ç†](#8-æ•…éšœåº”æ€¥å¤„ç†)
- [9. æ€§èƒ½ä¼˜åŒ–](#9-æ€§èƒ½ä¼˜åŒ–)
- [10. å®‰å…¨åŠ å›º](#10-å®‰å…¨åŠ å›º)

---

## 1. éƒ¨ç½²æ¶æ„è®¾è®¡

### 1.1 Kubernetesé›†ç¾¤æ¶æ„

#### ğŸ—ï¸ åŸºç¡€è®¾æ–½å±‚
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                K8s Master                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Control Plane Components          â”‚
â”‚  â€¢ API Server    â€¢ etcd     â€¢ Scheduler   â”‚
â”‚  â€¢ Controller Manager      â€¢ Cloud Manager â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ (Cluster Network)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Worker Nodes                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Node 1     â”‚   Node 2    â”‚    Node N       â”‚
â”‚â€¢ kubelet    â”‚ â€¢ kubelet   â”‚  â€¢ kubelet      â”‚
â”‚â€¢ kube-proxy â”‚ â€¢ kube-proxyâ”‚  â€¢ kube-proxy   â”‚
â”‚â€¢ Container  â”‚ â€¢ Container â”‚  â€¢ Container    â”‚
â”‚  Runtime    â”‚   Runtime   â”‚    Runtime      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”§ æ ¸å¿ƒç»„ä»¶éƒ¨ç½²æ¸…å•
| ç»„ä»¶ç±»å‹ | éƒ¨ç½²æ–¹å¼ | å®ä¾‹æ•°é‡ | èµ„æºè¦æ±‚ |
|---------|----------|----------|----------|
| **API Gateway** | Deployment | 3 | 2C4G |
| **Tenant Service** | Deployment | 2 | 1C2G |
| **Session Service** | Deployment | 3 | 2C4G |
| **Message Service** | Deployment | 3 | 2C4G |
| **Auth Service** | Deployment | 2 | 1C2G |
| **AstrBotå®ä¾‹** | åŠ¨æ€Deployment | N | 1C2G/ç§Ÿæˆ· |

### 1.2 ç½‘ç»œæ¶æ„è®¾è®¡

#### ğŸŒ ç½‘ç»œæ‹“æ‰‘å›¾
```mermaid
graph TB
    Internet[Internet] --> LB[Load Balancer]
    LB --> Ingress[Ingress Controller]
    
    subgraph "K8s Cluster"
        Ingress --> Gateway[API Gateway]
        Gateway --> TenantSvc[Tenant Service]
        Gateway --> SessionSvc[Session Service]
        Gateway --> MessageSvc[Message Service]
        Gateway --> AuthSvc[Auth Service]
        
        TenantSvc --> AstrBot1[AstrBot Instance 1]
        TenantSvc --> AstrBot2[AstrBot Instance 2]
        TenantSvc --> AstrBotN[AstrBot Instance N]
        
        MessageSvc --> Redis[(Redis Cluster)]
        SessionSvc --> PostgreSQL[(PostgreSQL)]
        
        AstrBot1 --> MinIO[(MinIO Cluster)]
        AstrBot2 --> MinIO
        AstrBotN --> MinIO
    end
```

#### ğŸ” å®‰å…¨ç»„ç­–ç•¥
```yaml
# ç½‘ç»œå®‰å…¨ç­–ç•¥ç¤ºä¾‹
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: saas-platform-security
spec:
  podSelector:
    matchLabels:
      app: saas-platform
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: kube-system  # å…è®¸æ¥è‡ªç³»ç»Ÿå‘½åç©ºé—´
    - podSelector:
        matchLabels:
          app: api-gateway   # å…è®¸æ¥è‡ªAPIç½‘å…³
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database      # å…è®¸è®¿é—®æ•°æ®åº“
  - to:
    - podSelector:
        matchLabels:
          app: redis         # å…è®¸è®¿é—®Redis
```

---

## 2. ç¯å¢ƒé…ç½®

### 2.1 å¤šç¯å¢ƒç®¡ç†

#### ğŸ“‹ ç¯å¢ƒé…ç½®çŸ©é˜µ
| ç¯å¢ƒ | ç›®çš„ | è§„æ¨¡ | æ•°æ®æº | ç›‘æ§çº§åˆ« |
|------|------|------|--------|----------|
| **å¼€å‘(dev)** | æ—¥å¸¸å¼€å‘æµ‹è¯• | 1èŠ‚ç‚¹ | æµ‹è¯•æ•°æ® | åŸºç¡€ç›‘æ§ |
| **æµ‹è¯•(test)** | é›†æˆæµ‹è¯•/QA | 2èŠ‚ç‚¹ | ä»¿çœŸæ•°æ® | å®Œæ•´ç›‘æ§ |
| **é¢„ç”Ÿäº§(staging)** | ç”Ÿäº§éªŒè¯ | 3èŠ‚ç‚¹ | è„±æ•ç”Ÿäº§æ•°æ® | ç”Ÿäº§çº§ç›‘æ§ |
| **ç”Ÿäº§(prod)** | æ­£å¼ç¯å¢ƒ | 5+èŠ‚ç‚¹ | çœŸå®æ•°æ® | å…¨é¢ç›‘æ§ |

#### âš™ï¸ ConfigMapé…ç½®ç®¡ç†
```yaml
# configmap-prod.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: saas-platform-config
  namespace: production
data:
  # æ•°æ®åº“é…ç½®
  DB_HOST: "postgresql-cluster.prod.svc.cluster.local"
  DB_PORT: "5432"
  DB_NAME: "saas_platform"
  REDIS_HOST: "redis-cluster.prod.svc.cluster.local"
  REDIS_PORT: "6379"
  
  # æœåŠ¡é…ç½®
  API_RATE_LIMIT: "1000"
  SESSION_TIMEOUT: "3600"
  MAX_ASTRBOT_INSTANCES: "1000"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "true"
  LOG_LEVEL: "INFO"
  TRACE_SAMPLING_RATE: "0.1"
```

#### ğŸ”’ Secretæ•æ„Ÿä¿¡æ¯ç®¡ç†
```yaml
# secret-prod.yaml
apiVersion: v1
kind: Secret
metadata:
  name: saas-platform-secrets
  namespace: production
type: Opaque
data:
  # Base64ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
  DB_PASSWORD: <base64-encoded-password>
  REDIS_PASSWORD: <base64-encoded-password>
  JWT_SECRET: <base64-encoded-jwt-secret>
  LLM_API_KEY: <base64-encoded-api-key>
  MINIO_ACCESS_KEY: <base64-encoded-access-key>
  MINIO_SECRET_KEY: <base64-encoded-secret-key>
```

### 2.2 åŸºç¡€è®¾æ–½ç»„ä»¶é…ç½®

#### ğŸ—„ï¸ PostgreSQLé›†ç¾¤é…ç½®
```yaml
# postgresql-ha.yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: postgresql-cluster
spec:
  instances: 3
  
  postgresql:
    parameters:
      max_connections: "200"
      shared_buffers: "256MB"
      effective_cache_size: "1GB"
      maintenance_work_mem: "64MB"
      checkpoint_completion_target: "0.9"
      wal_buffers: "16MB"
      default_statistics_target: "100"
      random_page_cost: "1.1"
      effective_io_concurrency: "200"
  
  resources:
    requests:
      memory: "1Gi"
      cpu: "1"
    limits:
      memory: "2Gi"
      cpu: "2"
  
  storage:
    size: "100Gi"
    storageClass: "fast-ssd"
  
  monitoring:
    enabled: true
```

#### ğŸ“Š Redisé›†ç¾¤é…ç½®
```yaml
# redis-cluster.yaml
apiVersion: redis.redis.opstreelabs.in/v1beta1
kind: RedisCluster
metadata:
  name: redis-cluster
spec:
  clusterSize: 6
  
  redisExporter:
    enabled: true
    image: "oliver006/redis_exporter:latest"
  
  storage:
    volumeClaimTemplate:
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: "50Gi"
        storageClassName: "fast-ssd"
  
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1"
      memory: "2Gi"
```

---

## 3. éƒ¨ç½²æµç¨‹

### 3.1 CI/CDæµæ°´çº¿

#### ğŸ”„ è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹
```mermaid
graph LR
    A[ä»£ç æ¨é€] --> B[æ„å»ºè§¦å‘]
    B --> C[å•å…ƒæµ‹è¯•]
    C --> D[ä»£ç æ‰«æ]
    D --> E[é•œåƒæ„å»º]
    E --> F[é•œåƒæ¨é€]
    F --> G[éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ]
    G --> H[é›†æˆæµ‹è¯•]
    H --> I{æµ‹è¯•é€šè¿‡?}
    I -->|æ˜¯| J[éƒ¨ç½²åˆ°é¢„ç”Ÿäº§]
    I -->|å¦| K[é€šçŸ¥å¼€å‘è€…]
    J --> L[ç”Ÿäº§éªŒè¯]
    L --> M[éƒ¨ç½²åˆ°ç”Ÿäº§]
```

#### ğŸ“¦ Dockeré•œåƒæ„å»ºç­–ç•¥
```dockerfile
# Dockerfile.saas-platform
FROM python:3.11-slim as builder

# å®‰è£…ä¾èµ–
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤šé˜¶æ®µæ„å»º - ç”Ÿäº§é•œåƒ
FROM python:3.11-slim

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# å¤åˆ¶åº”ç”¨ä»£ç 
WORKDIR /app
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin
COPY . .

# è®¾ç½®æƒé™
RUN chown -R appuser:appuser /app
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "app.main:app"]
```

### 3.2 Helm Chartéƒ¨ç½²

#### ğŸ“Š Helm Chartç»“æ„
```
helm-charts/
â”œâ”€â”€ saas-platform/
â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”œâ”€â”€ values.yaml
â”‚   â”œâ”€â”€ values-dev.yaml
â”‚   â”œâ”€â”€ values-staging.yaml
â”‚   â”œâ”€â”€ values-prod.yaml
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ deployment.yaml
â”‚       â”œâ”€â”€ service.yaml
â”‚       â”œâ”€â”€ ingress.yaml
â”‚       â”œâ”€â”€ configmap.yaml
â”‚       â”œâ”€â”€ secret.yaml
â”‚       â””â”€â”€ hpa.yaml
â””â”€â”€ astrbot-instance/
    â”œâ”€â”€ Chart.yaml
    â”œâ”€â”€ values.yaml
    â””â”€â”€ templates/
        â”œâ”€â”€ deployment.yaml
        â”œâ”€â”€ service.yaml
        â””â”€â”€ configmap.yaml
```

#### âš™ï¸ ç”Ÿäº§ç¯å¢ƒHelm Values
```yaml
# values-prod.yaml
replicaCount: 3

image:
  repository: saas-platform
  tag: "1.0.0"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "1000"
  hosts:
    - host: api.saas-platform.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: saas-platform-tls
      hosts:
        - api.saas-platform.com

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 1000m
    memory: 2Gi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# æ•°æ®åº“é…ç½®
postgresql:
  enabled: false  # ä½¿ç”¨å¤–éƒ¨PostgreSQLé›†ç¾¤
  external:
    host: "postgresql-cluster.prod.svc.cluster.local"
    port: 5432
    database: "saas_platform"

redis:
  enabled: false  # ä½¿ç”¨å¤–éƒ¨Redisé›†ç¾¤
  external:
    host: "redis-cluster.prod.svc.cluster.local"
    port: 6379
```

### 3.3 é›¶åœæœºéƒ¨ç½²ç­–ç•¥

#### ğŸ”„ æ»šåŠ¨æ›´æ–°é…ç½®
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: saas-platform
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 50%        # æœ€å¤šå¯ä»¥å¤šåˆ›å»º50%çš„Pod
      maxUnavailable: 25%  # æœ€å¤šå¯ä»¥æœ‰25%çš„Podä¸å¯ç”¨
  
  template:
    spec:
      containers:
      - name: saas-platform
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        lifecycle:
          preStop:
            exec:
              command:
                - /bin/sh
                - -c
                - "sleep 15"  # ç»™æ­£åœ¨å¤„ç†çš„è¯·æ±‚æ—¶é—´å®Œæˆ
```

---

## 4. ç›‘æ§ä¸å‘Šè­¦

### 4.1 Prometheusç›‘æ§é…ç½®

#### ğŸ“ˆ å…³é”®ç›‘æ§æŒ‡æ ‡
```yaml
# prometheus-rules.yaml
groups:
- name: saas-platform-alerts
  rules:
  # APIå“åº”æ—¶é—´å‘Šè­¦
  - alert: HighAPILatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "APIå“åº”æ—¶é—´è¿‡é«˜"
      description: "95%çš„APIè¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡500ms"
  
  # é”™è¯¯ç‡å‘Šè­¦
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "é”™è¯¯ç‡è¿‡é«˜"
      description: "5åˆ†é’Ÿå†…é”™è¯¯ç‡è¶…è¿‡5%"
  
  # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighMemoryUsage
    expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "å®¹å™¨å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%"
  
  # AstrBotå®ä¾‹ç¦»çº¿å‘Šè­¦
  - alert: AstrBotInstanceDown
    expr: up{job="astrbot-instance"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "AstrBotå®ä¾‹ç¦»çº¿"
      description: "AstrBotå®ä¾‹ {{ $labels.instance }} ä¸å¯è¾¾"
```

#### ğŸ“Š Grafanaä»ªè¡¨æ¿é…ç½®
```json
{
  "dashboard": {
    "title": "SaaSå¹³å°ç›‘æ§å¤§ç›˜",
    "panels": [
      {
        "title": "APIè¯·æ±‚QPS",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[1m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´åˆ†å¸ƒ",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(http_request_duration_seconds_bucket[5m])",
            "format": "heatmap"
          }
        ]
      },
      {
        "title": "æ´»è·ƒç§Ÿæˆ·æ•°é‡",
        "type": "stat",
        "targets": [
          {
            "expr": "count(count by (tenant_id) (rate(http_requests_total{tenant_id!=\"\"}[5m])))"
          }
        ]
      },
      {
        "title": "AstrBotå®ä¾‹çŠ¶æ€",
        "type": "table",
        "targets": [
          {
            "expr": "up{job=\"astrbot-instance\"}",
            "format": "table"
          }
        ]
      }
    ]
  }
}
```

### 4.2 å‘Šè­¦é€šçŸ¥é…ç½®

#### ğŸš¨ AlertManageré…ç½®
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@saas-platform.com'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
  - match:
      alertname: AstrBotInstanceDown
    receiver: 'astrbot-alerts'

receivers:
- name: 'default'
  email_configs:
  - to: 'ops-team@saas-platform.com'
    subject: '{{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      å‘Šè­¦: {{ .Annotations.summary }}
      è¯¦æƒ…: {{ .Annotations.description }}
      æ—¶é—´: {{ .StartsAt }}
      {{ end }}

- name: 'critical-alerts'
  email_configs:
  - to: 'ops-team@saas-platform.com,cto@saas-platform.com'
    subject: 'ğŸš¨ ç´§æ€¥å‘Šè­¦: {{ .GroupLabels.alertname }}'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/...'
    channel: '#critical-alerts'
    title: 'ç´§æ€¥å‘Šè­¦'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'astrbot-alerts'
  webhook_configs:
  - url: 'http://astrbot-manager.saas-platform.svc.cluster.local/webhook/alert'
    send_resolved: true
```

---

## 5. æ—¥å¿—ç®¡ç†

### 5.1 ELK Stackéƒ¨ç½²

#### ğŸ“„ Fluentdæ—¥å¿—æ”¶é›†é…ç½®
```yaml
# fluentd-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
      read_from_head true
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    # è¿‡æ»¤å’Œè§£æSaaSå¹³å°æ—¥å¿—
    <filter kubernetes.var.log.containers.**saas-platform**.log>
      @type parser
      key_name log
      <parse>
        @type json
        time_key timestamp
        time_format %Y-%m-%d %H:%M:%S
      </parse>
    </filter>
    
    # æ·»åŠ ç¯å¢ƒæ ‡ç­¾
    <filter kubernetes.**>
      @type record_transformer
      <record>
        environment "#{ENV['ENVIRONMENT']}"
        cluster "#{ENV['CLUSTER_NAME']}"
      </record>
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name k8s-logs
      type_name _doc
      include_tag_key true
      tag_key @log_name
      flush_interval 1s
    </match>
```

### 5.2 ç»“æ„åŒ–æ—¥å¿—è§„èŒƒ

#### ğŸ“‹ åº”ç”¨æ—¥å¿—æ ¼å¼
```python
# åº”ç”¨æ—¥å¿—é…ç½®ç¤ºä¾‹
import structlog
import logging

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

# ä½¿ç”¨ç¤ºä¾‹
logger = structlog.get_logger()

# ä¸šåŠ¡æ—¥å¿—
logger.info(
    "message_created",
    tenant_id="tenant_123",
    user_id="user_456",
    session_id="session_789",
    message_id="msg_abc",
    content_length=100,
    processing_time_ms=45
)

# é”™è¯¯æ—¥å¿—
logger.error(
    "database_connection_failed",
    tenant_id="tenant_123",
    error_code="DB_CONN_TIMEOUT",
    retry_count=3,
    database_host="postgresql-cluster.prod",
    exc_info=True
)
```

---

## 6. æ•°æ®å¤‡ä»½ä¸ç¾å¤‡

### 6.1 æ•°æ®åº“å¤‡ä»½ç­–ç•¥

#### ğŸ’¾ PostgreSQLå¤‡ä»½é…ç½®
```yaml
# postgresql-backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgres-backup
            image: postgres:13
            command:
            - /bin/bash
            - -c
            - |
              # å…¨é‡å¤‡ä»½
              pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME | gzip > /backup/$(date +%Y%m%d_%H%M%S)_full.sql.gz
              
              # æ¸…ç†7å¤©å‰çš„å¤‡ä»½
              find /backup -name "*.sql.gz" -mtime +7 -delete
              
              # ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
              aws s3 cp /backup/ s3://saas-platform-backups/postgresql/ --recursive --exclude "*" --include "$(date +%Y%m%d)*"
            env:
            - name: DB_HOST
              value: "postgresql-cluster.prod.svc.cluster.local"
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-secret
                  key: username
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-secret
                  key: password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

### 6.2 ç¾éš¾æ¢å¤è®¡åˆ’

#### ğŸ”„ RTO/RPOç›®æ ‡
| æœåŠ¡ç±»å‹ | RTOç›®æ ‡ | RPOç›®æ ‡ | æ¢å¤ç­–ç•¥ |
|---------|---------|---------|----------|
| **APIæœåŠ¡** | < 5åˆ†é’Ÿ | 0 | å¤šAZéƒ¨ç½²,è‡ªåŠ¨æ•…éšœè½¬ç§» |
| **æ•°æ®åº“** | < 30åˆ†é’Ÿ | < 15åˆ†é’Ÿ | ä¸»ä»å¤åˆ¶,å¿«é€Ÿåˆ‡æ¢ |
| **æ–‡ä»¶å­˜å‚¨** | < 15åˆ†é’Ÿ | < 5åˆ†é’Ÿ | è·¨åŒºåŸŸå¤åˆ¶ |
| **å…¨ç³»ç»Ÿ** | < 2å°æ—¶ | < 1å°æ—¶ | è·¨åŒºåŸŸç¾å¤‡ |

#### ğŸš¨ ç¾éš¾æ¢å¤æµç¨‹
```bash
#!/bin/bash
# disaster-recovery.sh

# 1. è¯„ä¼°ç¾éš¾å½±å“
echo "=== ç¾éš¾æ¢å¤æµç¨‹å¯åŠ¨ ==="
echo "è¯„ä¼°å½“å‰æœåŠ¡çŠ¶æ€..."

# æ£€æŸ¥ä¸»æ•°æ®ä¸­å¿ƒçŠ¶æ€
kubectl --context=main-cluster get nodes
MAIN_CLUSTER_STATUS=$?

if [ $MAIN_CLUSTER_STATUS -ne 0 ]; then
    echo "ä¸»é›†ç¾¤ä¸å¯è¾¾ï¼Œå¯åŠ¨ç¾å¤‡åˆ‡æ¢..."
    
    # 2. åˆ‡æ¢åˆ°ç¾å¤‡æ•°æ®ä¸­å¿ƒ
    kubectl config use-context disaster-recovery-cluster
    
    # 3. å¯åŠ¨ç¾å¤‡æœåŠ¡
    echo "å¯åŠ¨ç¾å¤‡ç¯å¢ƒæœåŠ¡..."
    helm upgrade --install saas-platform ./helm-charts/saas-platform \
        -f values-dr.yaml \
        --namespace production
    
    # 4. æ•°æ®åº“æ¢å¤
    echo "æ¢å¤æ•°æ®åº“..."
    kubectl apply -f database-restore-job.yaml
    
    # 5. æ›´æ–°DNSæŒ‡å‘
    echo "æ›´æ–°DNSè®°å½•åˆ°ç¾å¤‡ç¯å¢ƒ..."
    # è°ƒç”¨DNS APIæ›´æ–°è®°å½•
    
    # 6. éªŒè¯æœåŠ¡å¯ç”¨æ€§
    echo "éªŒè¯æœåŠ¡æ¢å¤çŠ¶æ€..."
    curl -f https://api.saas-platform.com/health
    
    echo "=== ç¾éš¾æ¢å¤å®Œæˆ ==="
else
    echo "ä¸»é›†ç¾¤æ­£å¸¸ï¼Œå–æ¶ˆç¾éš¾æ¢å¤æµç¨‹"
fi
```

---

## 7. ç‰ˆæœ¬å‡çº§ä¸å›æ»š

### 7.1 è“ç»¿éƒ¨ç½²

#### ğŸ”„ è“ç»¿åˆ‡æ¢æµç¨‹
```bash
#!/bin/bash
# blue-green-deployment.sh

NEW_VERSION=$1
CURRENT_ENV=$(kubectl get service saas-platform-active -o jsonpath='{.spec.selector.version}')

echo "å½“å‰ç¯å¢ƒ: $CURRENT_ENV"
echo "éƒ¨ç½²ç‰ˆæœ¬: $NEW_VERSION"

# ç¡®å®šæ–°ç¯å¢ƒé¢œè‰²
if [ "$CURRENT_ENV" = "blue" ]; then
    NEW_ENV="green"
else
    NEW_ENV="blue"
fi

echo "éƒ¨ç½²åˆ° $NEW_ENV ç¯å¢ƒ..."

# 1. éƒ¨ç½²æ–°ç‰ˆæœ¬åˆ°éæ´»è·ƒç¯å¢ƒ
helm upgrade --install saas-platform-$NEW_ENV ./helm-charts/saas-platform \
    --set image.tag=$NEW_VERSION \
    --set environment=$NEW_ENV \
    --namespace production

# 2. ç­‰å¾…æ–°ç¯å¢ƒå°±ç»ª
kubectl wait --for=condition=available --timeout=300s deployment/saas-platform-$NEW_ENV

# 3. å¥åº·æ£€æŸ¥
echo "æ‰§è¡Œå¥åº·æ£€æŸ¥..."
NEW_ENV_POD=$(kubectl get pod -l app=saas-platform,environment=$NEW_ENV -o jsonpath='{.items[0].metadata.name}')
kubectl exec $NEW_ENV_POD -- curl -f http://localhost:8000/health

if [ $? -eq 0 ]; then
    # 4. åˆ‡æ¢æµé‡
    echo "åˆ‡æ¢æµé‡åˆ° $NEW_ENV ç¯å¢ƒ..."
    kubectl patch service saas-platform-active -p '{"spec":{"selector":{"environment":"'$NEW_ENV'"}}}'
    
    # 5. éªŒè¯åˆ‡æ¢æˆåŠŸ
    sleep 10
    curl -f https://api.saas-platform.com/health
    
    if [ $? -eq 0 ]; then
        echo "éƒ¨ç½²æˆåŠŸï¼Œåœæ­¢æ—§ç¯å¢ƒ..."
        kubectl scale deployment saas-platform-$CURRENT_ENV --replicas=0
        echo "è“ç»¿éƒ¨ç½²å®Œæˆ"
    else
        echo "éªŒè¯å¤±è´¥ï¼Œå›æ»š..."
        kubectl patch service saas-platform-active -p '{"spec":{"selector":{"environment":"'$CURRENT_ENV'"}}}'
    fi
else
    echo "å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå–æ¶ˆéƒ¨ç½²"
    kubectl delete deployment saas-platform-$NEW_ENV
fi
```

### 7.2 æ•°æ®åº“è¿ç§»ç®¡ç†

#### ğŸ“Š Schemaè¿ç§»è„šæœ¬
```python
# database/migrations/001_add_tenant_table.py
"""
æ·»åŠ ç§Ÿæˆ·ç®¡ç†è¡¨
"""

def upgrade():
    """å‡çº§æ•°æ®åº“Schema"""
    op.create_table(
        'tenants',
        sa.Column('id', sa.String(36), primary_key=True),
        sa.Column('name', sa.String(100), nullable=False),
        sa.Column('email', sa.String(255), nullable=False, unique=True),
        sa.Column('plan', sa.String(20), nullable=False),
        sa.Column('status', sa.String(20), nullable=False, default='active'),
        sa.Column('created_at', sa.DateTime, nullable=False, default=datetime.utcnow),
        sa.Column('updated_at', sa.DateTime, nullable=False, default=datetime.utcnow),
        sa.Index('idx_tenant_email', 'email'),
        sa.Index('idx_tenant_status', 'status')
    )

def downgrade():
    """å›æ»šæ•°æ®åº“Schema"""
    op.drop_table('tenants')
```

---

## 8. æ•…éšœåº”æ€¥å¤„ç†

### 8.1 æ•…éšœåˆ†ç±»ä¸å¤„ç†æµç¨‹

#### ğŸš¨ æ•…éšœç­‰çº§å®šä¹‰
| ç­‰çº§ | å½±å“èŒƒå›´ | å“åº”æ—¶é—´ | å¤„ç†ç­–ç•¥ |
|------|----------|----------|----------|
| **P0 - ä¸¥é‡** | å…¨æœåŠ¡ä¸å¯ç”¨ | 15åˆ†é’Ÿ | ç«‹å³å¤„ç†,å…¨å‘˜å“åº” |
| **P1 - é«˜** | æ ¸å¿ƒåŠŸèƒ½å¼‚å¸¸ | 30åˆ†é’Ÿ | ä¼˜å…ˆå¤„ç†,æŠ€æœ¯è´Ÿè´£äººå“åº” |
| **P2 - ä¸­** | éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ | 2å°æ—¶ | æ­£å¸¸å¤„ç†,ç›¸å…³å¼€å‘è€…å“åº” |
| **P3 - ä½** | æ€§èƒ½å½±å“ | 1å¤© | è®¡åˆ’å¤„ç†,æ—¥å¸¸ç»´æŠ¤ |

#### ğŸ”§ æ•…éšœå¤„ç†Runbook
```yaml
# runbooks/database-connection-failure.yaml
title: "æ•°æ®åº“è¿æ¥æ•…éšœå¤„ç†"
severity: "P1"
symptoms:
  - "APIè¿”å›500é”™è¯¯"
  - "æ—¥å¿—å‡ºç°æ•°æ®åº“è¿æ¥è¶…æ—¶"
  - "è¿æ¥æ± è€—å°½å‘Šè­¦"

investigation_steps:
  1. "æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€: kubectl get pods -l app=postgresql"
  2. "æŸ¥çœ‹æ•°æ®åº“è¿æ¥æ•°: SELECT count(*) FROM pg_stat_activity;"
  3. "æ£€æŸ¥æ…¢æŸ¥è¯¢: SELECT * FROM pg_stat_activity WHERE state = 'active' AND query_start < now() - interval '30 seconds';"
  4. "æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—: kubectl logs postgresql-0 -f"

resolution_steps:
  1. "é‡å¯åº”ç”¨Podé‡Šæ”¾è¿æ¥: kubectl rollout restart deployment/saas-platform"
  2. "å¦‚æœæ•°æ®åº“Podå¼‚å¸¸ï¼Œé‡å¯æ•°æ®åº“: kubectl delete pod postgresql-0"
  3. "ä¸´æ—¶æ‰©å®¹æ•°æ®åº“è¿æ¥æ± : kubectl patch configmap app-config --patch '{\"data\":{\"DB_POOL_SIZE\":\"50\"}}'"
  4. "ç›‘æ§ç³»ç»Ÿæ¢å¤çŠ¶æ€"

escalation:
  - "15åˆ†é’Ÿå†…æœªè§£å†³ï¼Œé€šçŸ¥æŠ€æœ¯æ€»ç›‘"
  - "30åˆ†é’Ÿå†…æœªè§£å†³ï¼Œå¯åŠ¨ç´§æ€¥ä¼šè®®"
```

### 8.2 è‡ªåŠ¨æ•…éšœæ¢å¤

#### ğŸ¤– è‡ªæ„ˆè„šæœ¬
```python
# scripts/auto-healing.py
import kubernetes
import time
import logging

class AutoHealer:
    def __init__(self):
        kubernetes.config.load_incluster_config()
        self.v1 = kubernetes.client.CoreV1Api()
        self.apps_v1 = kubernetes.client.AppsV1Api()
        
    def check_pod_health(self):
        """æ£€æŸ¥Podå¥åº·çŠ¶æ€å¹¶è‡ªåŠ¨é‡å¯æ•…éšœPod"""
        pods = self.v1.list_namespaced_pod(
            namespace="production",
            label_selector="app=saas-platform"
        )
        
        for pod in pods.items:
            if self.is_pod_unhealthy(pod):
                logging.warning(f"å‘ç°æ•…éšœPod: {pod.metadata.name}")
                self.restart_pod(pod)
    
    def is_pod_unhealthy(self, pod):
        """åˆ¤æ–­Podæ˜¯å¦ä¸å¥åº·"""
        # æ£€æŸ¥é‡å¯æ¬¡æ•°
        restart_count = sum(
            container.restart_count for container in pod.status.container_statuses or []
        )
        if restart_count > 5:
            return True
            
        # æ£€æŸ¥å°±ç»ªçŠ¶æ€
        for condition in pod.status.conditions or []:
            if condition.type == "Ready" and condition.status != "True":
                # å¦‚æœè¶…è¿‡5åˆ†é’Ÿæœªå°±ç»ª
                if time.time() - condition.last_transition_time.timestamp() > 300:
                    return True
        
        return False
    
    def restart_pod(self, pod):
        """é‡å¯æ•…éšœPod"""
        try:
            self.v1.delete_namespaced_pod(
                name=pod.metadata.name,
                namespace=pod.metadata.namespace
            )
            logging.info(f"å·²é‡å¯Pod: {pod.metadata.name}")
            
            # å‘é€å‘Šè­¦é€šçŸ¥
            self.send_alert(f"è‡ªåŠ¨é‡å¯äº†æ•…éšœPod: {pod.metadata.name}")
            
        except Exception as e:
            logging.error(f"é‡å¯Podå¤±è´¥: {e}")
    
    def send_alert(self, message):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # é›†æˆå‘Šè­¦ç³»ç»ŸAPI
        pass

if __name__ == "__main__":
    healer = AutoHealer()
    
    while True:
        try:
            healer.check_pod_health()
        except Exception as e:
            logging.error(f"è‡ªæ„ˆæ£€æŸ¥å¤±è´¥: {e}")
        
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

---

## ğŸ“‹ è¿ç»´æ€»ç»“

### âœ… è¿ç»´æ ¸å¿ƒè¦ç‚¹
- **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**: å°½å¯èƒ½è‡ªåŠ¨åŒ–é‡å¤æ€§æ“ä½œ
- **ç›‘æ§é©±åŠ¨**: åŸºäºç›‘æ§æ•°æ®è¿›è¡Œè¿ç»´å†³ç­–
- **é¢„é˜²ä¸ºä¸»**: é€šè¿‡ç›‘æ§å’Œå‘Šè­¦æå‰å‘ç°é—®é¢˜
- **å¿«é€Ÿæ¢å¤**: å»ºç«‹å®Œå–„çš„æ•…éšœæ¢å¤æœºåˆ¶

### âœ… å…³é”®æˆåŠŸæŒ‡æ ‡
- **å¯ç”¨æ€§**: > 99.9% (æœˆåº¦)
- **MTTR**: < 30åˆ†é’Ÿ (å¹³å‡æ•…éšœæ¢å¤æ—¶é—´)
- **MTBF**: > 720å°æ—¶ (å¹³å‡æ•…éšœé—´éš”)
- **éƒ¨ç½²æˆåŠŸç‡**: > 95%

---

**è¿ç»´æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´  
**ä¸‹ä¸€æ­¥**: è¿ç»´å·¥å…·é›†æˆå’Œå›¢é˜ŸåŸ¹è®­