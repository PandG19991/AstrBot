#!/usr/bin/env python3
"""
æ–‡ä»¶é•¿åº¦æ£€æŸ¥å·¥å…· - ç¡®ä¿ä»£ç æ–‡ä»¶é€‚åˆAIååŒå¼€å‘
é€‚ç”¨äºAstrBot SaaSé¡¹ç›®ï¼Œæ£€æŸ¥Pythonæ–‡ä»¶è¡Œæ•°æ˜¯å¦ç¬¦åˆè§„èŒƒ
"""

import os
import sys
from pathlib import Path
from typing import List, Tuple, Dict
import argparse
import json


def count_effective_lines(file_path: Path) -> int:
    """
    è®¡ç®—æœ‰æ•ˆä»£ç è¡Œæ•°ï¼Œæ’é™¤ç©ºè¡Œå’Œçº¯æ³¨é‡Šè¡Œ
    
    Args:
        file_path: Pythonæ–‡ä»¶è·¯å¾„
        
    Returns:
        æœ‰æ•ˆä»£ç è¡Œæ•°
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        # å¤„ç†ç¼–ç é—®é¢˜
        with open(file_path, 'r', encoding='gbk') as f:
            lines = f.readlines()
    
    effective_lines = 0
    in_multiline_string = False
    string_delimiter = None
    
    for line in lines:
        stripped = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not stripped:
            continue
            
        # æ£€æŸ¥å¤šè¡Œå­—ç¬¦ä¸²
        if '"""' in stripped or "'''" in stripped:
            if stripped.count('"""') % 2 == 1 or stripped.count("'''") % 2 == 1:
                in_multiline_string = not in_multiline_string
                string_delimiter = '"""' if '"""' in stripped else "'''"
            
        # å¦‚æœåœ¨å¤šè¡Œå­—ç¬¦ä¸²ä¸­ï¼Œè·³è¿‡
        if in_multiline_string:
            continue
            
        # è·³è¿‡çº¯æ³¨é‡Šè¡Œ
        if stripped.startswith('#'):
            continue
            
        # è®¡ç®—æœ‰æ•ˆä»£ç è¡Œ
        effective_lines += 1
    
    return effective_lines


def analyze_file_complexity(file_path: Path) -> Dict[str, int]:
    """
    åˆ†ææ–‡ä»¶å¤æ‚åº¦æŒ‡æ ‡
    
    Args:
        file_path: Pythonæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤æ‚åº¦æŒ‡æ ‡å­—å…¸
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        with open(file_path, 'r', encoding='gbk') as f:
            content = f.read()
    
    metrics = {
        'total_lines': len(content.splitlines()),
        'effective_lines': count_effective_lines(file_path),
        'classes': content.count('class '),
        'functions': content.count('def ') + content.count('async def '),
        'imports': content.count('import ') + content.count('from '),
    }
    
    return metrics


def check_directory_files(
    directory: str, 
    max_lines: int = 500,
    warning_threshold: float = 0.8,
    exclude_patterns: List[str] = None
) -> Tuple[List[str], List[str], List[Dict]]:
    """
    æ£€æŸ¥ç›®å½•ä¸‹æ‰€æœ‰Pythonæ–‡ä»¶çš„è¡Œæ•°
    
    Args:
        directory: è¦æ£€æŸ¥çš„ç›®å½•è·¯å¾„
        max_lines: æœ€å¤§è¡Œæ•°é™åˆ¶
        warning_threshold: è­¦å‘Šé˜ˆå€¼æ¯”ä¾‹
        exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼
        
    Returns:
        (è­¦å‘Šåˆ—è¡¨, é”™è¯¯åˆ—è¡¨, è¯¦ç»†åˆ†æåˆ—è¡¨)
    """
    if exclude_patterns is None:
        exclude_patterns = ['__pycache__', '.git', 'migrations', 'alembic/versions']
    
    warnings = []
    errors = []
    analysis = []
    
    warning_limit = int(max_lines * warning_threshold)
    
    for py_file in Path(directory).rglob("*.py"):
        # è·³è¿‡æ’é™¤çš„æ–‡ä»¶
        if any(pattern in str(py_file) for pattern in exclude_patterns):
            continue
            
        # è·³è¿‡ç‰¹æ®Šæ–‡ä»¶
        if py_file.name.startswith("__") and py_file.name.endswith("__.py"):
            continue
            
        metrics = analyze_file_complexity(py_file)
        relative_path = py_file.relative_to(Path(directory).parent)
        
        analysis.append({
            'file': str(relative_path),
            'metrics': metrics
        })
        
        effective_lines = metrics['effective_lines']
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if effective_lines > max_lines:
            errors.append({
                'file': str(relative_path),
                'lines': effective_lines,
                'message': f"âŒ {relative_path}: {effective_lines} è¡Œ (è¶…è¿‡ {max_lines} è¡Œé™åˆ¶)",
                'suggestion': get_refactor_suggestion(py_file, metrics)
            })
        elif effective_lines > warning_limit:
            warnings.append({
                'file': str(relative_path),
                'lines': effective_lines,
                'message': f"âš ï¸ {relative_path}: {effective_lines} è¡Œ (æ¥è¿‘ {max_lines} è¡Œé™åˆ¶)",
                'suggestion': "å»ºè®®å¼€å§‹è§„åˆ’æ¨¡å—æ‹†åˆ†"
            })
    
    return warnings, errors, analysis


def get_refactor_suggestion(file_path: Path, metrics: Dict[str, int]) -> str:
    """
    æ ¹æ®æ–‡ä»¶å†…å®¹æä¾›é‡æ„å»ºè®®
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        metrics: æ–‡ä»¶å¤æ‚åº¦æŒ‡æ ‡
        
    Returns:
        é‡æ„å»ºè®®
    """
    suggestions = []
    
    if metrics['classes'] > 3:
        suggestions.append("è€ƒè™‘å°†å¤šä¸ªç±»æ‹†åˆ†åˆ°ä¸åŒæ–‡ä»¶")
    
    if metrics['functions'] > 20:
        suggestions.append("å‡½æ•°è¿‡å¤šï¼Œè€ƒè™‘æŒ‰åŠŸèƒ½åˆ†ç»„åˆ°å­æ¨¡å—")
    
    if 'service' in file_path.name.lower():
        suggestions.append("æœåŠ¡ç±»å»ºè®®æŒ‰èŒè´£æ‹†åˆ†ï¼šcoreã€notificationã€analyticsç­‰")
    
    if 'router' in file_path.name.lower() or 'api' in file_path.name.lower():
        suggestions.append("APIè·¯ç”±å»ºè®®æŒ‰èµ„æºç±»å‹æ‹†åˆ†")
    
    if not suggestions:
        suggestions.append("å»ºè®®æŒ‰å•ä¸€èŒè´£åŸåˆ™æ‹†åˆ†åŠŸèƒ½æ¨¡å—")
    
    return "; ".join(suggestions)


def generate_report(warnings: List[Dict], errors: List[Dict], analysis: List[Dict], output_format: str = 'console'):
    """
    ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
    
    Args:
        warnings: è­¦å‘Šåˆ—è¡¨
        errors: é”™è¯¯åˆ—è¡¨
        analysis: è¯¦ç»†åˆ†æåˆ—è¡¨
        output_format: è¾“å‡ºæ ¼å¼ ('console', 'json', 'markdown')
    """
    if output_format == 'console':
        print("ğŸ” æ–‡ä»¶é•¿åº¦æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 50)
        
        if errors:
            print(f"\nâŒ å‘ç° {len(errors)} ä¸ªæ–‡ä»¶è¶…è¿‡è¡Œæ•°é™åˆ¶:")
            for error in errors:
                print(f"   {error['message']}")
                print(f"   ğŸ’¡ å»ºè®®: {error['suggestion']}")
                print()
        
        if warnings:
            print(f"\nâš ï¸ å‘ç° {len(warnings)} ä¸ªæ–‡ä»¶æ¥è¿‘è¡Œæ•°é™åˆ¶:")
            for warning in warnings:
                print(f"   {warning['message']}")
                print(f"   ğŸ’¡ å»ºè®®: {warning['suggestion']}")
                print()
        
        if not errors and not warnings:
            print("\nâœ… æ‰€æœ‰æ–‡ä»¶éƒ½ç¬¦åˆè¡Œæ•°è§„èŒƒï¼")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_files = len(analysis)
        avg_lines = sum(item['metrics']['effective_lines'] for item in analysis) / total_files if total_files > 0 else 0
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"   å¹³å‡è¡Œæ•°: {avg_lines:.1f}")
        print(f"   æœ€å¤§æ–‡ä»¶: {max(analysis, key=lambda x: x['metrics']['effective_lines'])['file'] if analysis else 'N/A'}")
        
    elif output_format == 'json':
        report = {
            'summary': {
                'total_files': len(analysis),
                'warnings': len(warnings),
                'errors': len(errors)
            },
            'warnings': warnings,
            'errors': errors,
            'analysis': analysis
        }
        print(json.dumps(report, indent=2, ensure_ascii=False))
    
    elif output_format == 'markdown':
        print("# æ–‡ä»¶é•¿åº¦æ£€æŸ¥æŠ¥å‘Š\n")
        
        if errors:
            print("## âŒ è¶…è¿‡é™åˆ¶çš„æ–‡ä»¶\n")
            for error in errors:
                print(f"- **{error['file']}**: {error['lines']} è¡Œ")
                print(f"  - ğŸ’¡ {error['suggestion']}\n")
        
        if warnings:
            print("## âš ï¸ æ¥è¿‘é™åˆ¶çš„æ–‡ä»¶\n")
            for warning in warnings:
                print(f"- **{warning['file']}**: {warning['lines']} è¡Œ")
                print(f"  - ğŸ’¡ {warning['suggestion']}\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ£€æŸ¥Pythonæ–‡ä»¶è¡Œæ•°æ˜¯å¦ç¬¦åˆAIååŒå¼€å‘è§„èŒƒ')
    parser.add_argument('directory', help='è¦æ£€æŸ¥çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--max-lines', type=int, default=500, help='æœ€å¤§è¡Œæ•°é™åˆ¶ (é»˜è®¤: 500)')
    parser.add_argument('--warning-threshold', type=float, default=0.8, help='è­¦å‘Šé˜ˆå€¼æ¯”ä¾‹ (é»˜è®¤: 0.8)')
    parser.add_argument('--format', choices=['console', 'json', 'markdown'], default='console', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--exclude', nargs='*', default=['__pycache__', '.git', 'migrations', 'alembic/versions'], 
                       help='æ’é™¤çš„ç›®å½•æ¨¡å¼')
    parser.add_argument('--ci', action='store_true', help='CIæ¨¡å¼ï¼šå‘ç°é”™è¯¯æ—¶é€€å‡ºç ä¸º1')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.directory):
        print(f"âŒ é”™è¯¯: ç›®å½• '{args.directory}' ä¸å­˜åœ¨")
        sys.exit(1)
    
    # æ‰§è¡Œæ£€æŸ¥
    warnings, errors, analysis = check_directory_files(
        args.directory,
        args.max_lines,
        args.warning_threshold,
        args.exclude
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(warnings, errors, analysis, args.format)
    
    # CIæ¨¡å¼ï¼šæœ‰é”™è¯¯æ—¶é€€å‡º
    if args.ci and errors:
        sys.exit(1)


if __name__ == "__main__":
    main() 